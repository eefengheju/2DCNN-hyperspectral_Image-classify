{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.载入数据"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1导入南瓜数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from preprocessSpectral import preprocessSpectral\n",
    "from  matplotlib import pyplot as plt\n",
    "import sys\n",
    "import zipfile\n",
    "datas=pd.read_excel('shui.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guangpu=datas.iloc[:,0:200]\n",
    "guangpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water1=datas.iloc[:,200:201]\n",
    "water1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water2=datas.iloc[:,201:202]\n",
    "water2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water3=datas.iloc[:,202:203]\n",
    "water3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ovr分类使用\n",
    "labels = datas['label']\n",
    "datas = datas.drop(columns='label')\n",
    "datalabels = pd.concat([datas,labels],axis=1)\n",
    "datalabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = datas.drop(columns='label')\n",
    "datalabels = pd.concat([datas,labels],axis=1)\n",
    "datalabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.生成测试集验证集"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1带PCA降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10) #降到 2 维\n",
    "pca.fit(guangpu)\n",
    "PCA(n_components=10)\n",
    "PCA10=pca.transform(guangpu) # 降维后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca10 = pd.DataFrame(PCA10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca10.to_excel('pca10.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 直接划分训练集和测试集"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1把光谱和选择的标签拼接起来，可以选择water1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas= pd.concat([guangpu,water1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = []\n",
    "train_label = []\n",
    "test_data = []\n",
    "test_label = []\n",
    "\n",
    "traindata,testdata = train_test_split(datas,test_size=0.2,random_state=0,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.append(traindata.iloc[:,:-1])\n",
    "train_label.append(traindata['label'])\n",
    "test_data.append(testdata.iloc[:,:-1])\n",
    "test_label.append(testdata['label'])\n",
    "    \n",
    "# train_data_all = pd.concat(train_data,axis=0)\n",
    "# test_data_all = pd.concat(test_data,axis=0)\n",
    "# train_label_all = pd.concat(train_label,axis=0)\n",
    "# test_label_all = pd.concat(test_label,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_all = pd.concat(train_data)\n",
    "test_data_all = pd.concat(test_data)\n",
    "train_label_all = pd.concat(train_label)\n",
    "test_label_all = pd.concat(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_all.to_excel('train_water3.xlsx')\n",
    "test_data_all.to_excel('test_water3.xlsx')\n",
    "train_label_all.to_excel('trainlabel_water3.xlsx')\n",
    "test_label_all.to_excel('testlabel_water3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.2查看数据差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(50,50))\n",
    "corr = datalabels.corr()\n",
    "ax = sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap=\"RdYlGn\",annot=False)\n",
    "plt.title(\"Correlation between variables\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.建模"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 如果需要载入旧模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "# clf = DecisionTreeClassifier(random_state=0)\n",
    "# rfc = RandomForestClassifier(random_state=0)\n",
    "# rfc = rfc.fit(train_data_all,train_label_all)\n",
    "# 载入\n",
    "rfc = joblib.load('hyperdata/models/clf.pkl')\n",
    "y_pred = rfc.predict(test_data_all)\n",
    "print(classification_report(test_label_all, y_pred))\n",
    "print(accuracy_score(test_label_all, y_pred))\n",
    "rfc.score(test_data_all,test_label_all)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 建立模型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.1找模型-导入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "from sklearn import linear_model\n",
    "model_LinearRegression = linear_model.LinearRegression()\n",
    "#Decision Tree Regressor\n",
    "from sklearn import tree\n",
    "model_DecisionTreeRegressor = tree.DecisionTreeRegressor()\n",
    "#SVM Regressor\n",
    "from sklearn import svm\n",
    "model_SVR = svm.SVR()\n",
    "#K Neighbors Regressor\n",
    "from sklearn import neighbors\n",
    "model_KNeighborsRegressor = neighbors.KNeighborsRegressor()\n",
    "#Random Forest Regressor\n",
    "from sklearn import ensemble\n",
    "model_RandomForestRegressor = ensemble.RandomForestRegressor(n_estimators=20)\n",
    "#Adaboost Regressor\n",
    "from sklearn import ensemble\n",
    "model_AdaBoostRegressor = ensemble.AdaBoostRegressor(n_estimators=50)\n",
    "#Gradient Boosting Random Forest Regressor\n",
    "from sklearn import ensemble\n",
    "model_GradientBoostingRegressor = ensemble.GradientBoostingRegressor(n_estimators=100)\n",
    "#bagging Regressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "model_BaggingRegressor = BaggingRegressor()\n",
    "#ExtraTree Regressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "model_ExtraTreeRegressor = ExtraTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#回归\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#分类\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#回归模型 Ridge Regression,    Lasso Regression ,Logistic Regression,ElasticNet\n",
    "#\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #  忽略弹出的warnings信息\n",
    "\n",
    "# clf = OneVsOneClassifier(LinearSVC(),n_jobs=-1)\n",
    "models = [\n",
    " PLSRegression(),\n",
    " AdaBoostRegressor(),\n",
    " GradientBoostingRegressor(),\n",
    " BaggingRegressor(),\n",
    " ExtraTreeRegressor(),\n",
    " DecisionTreeRegressor(),\n",
    " SVR()\n",
    "]\n",
    "\n",
    "#MAE,MSE,\n",
    "result = pd.DataFrame(columns=['model','explained_variance_score', 'mean_absolute_error', 'mean_squared_error',' r2_score'])\n",
    "for model in models:\n",
    "    clf = model\n",
    "    clf.fit(train_data_all,train_label_all)\n",
    "    y_pred = clf.predict(test_data_all)\n",
    "    print(model.__class__)\n",
    "    joblib.dump(clf, 'hyperdata/outmodels/OVR-models/'+model.__class__.__name__+'.pkl')\n",
    "        \n",
    "    result = result.append(pd.Series({\n",
    "        'model' : model.__class__,\n",
    "        'explained_variance_score':explained_variance_score(test_label_all,y_pred),\n",
    "        'mean_absolute_error':mean_absolute_error(test_label_all, y_pred),\n",
    "        'mean_squared_error':mean_squared_error(test_label_all, y_pred),\n",
    "        'r2_score':r2_score(test_label_all,y_pred)\n",
    "        }),ignore_index=True)\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.2建立PLS模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 假设你已经准备好了特征数据X和目标变量Y\n",
    "\n",
    "# 将数据集划分为训练集和测试集\n",
    "# train_data_all,train_label_all\n",
    "# 对特征数据进行标准化\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 初始化PLS回归模型\n",
    "pls = PLSRegression(n_components=9)  # 设置n_components为希望保留的主成分个数\n",
    "\n",
    "# 训练PLS回归模型\n",
    "pls.fit(train_data_all,train_label_all)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = pls.predict(test_data_all)\n",
    "\n",
    "# 计算回归指标\n",
    "mse = mean_squared_error(test_label_all, y_pred)\n",
    "r2 = r2_score(test_label_all, y_pred)\n",
    "evs=explained_variance_score(test_label_all,y_pred)\n",
    "mae=mean_absolute_error(test_label_all, y_pred)\n",
    "\n",
    "# 打印回归指标\n",
    "print(\"Mean Squared Error (MSE): {:.2f}\".format(mse))\n",
    "print(\"R-squared (R2): {:.2f}\".format(r2))\n",
    "print(\"Mean absolute Error (MAE): {:.2f}\".format(mae))\n",
    "print(\"Explained_Variance_Score: {:.2f}\".format(evs))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.3导入训练好的pls模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pls, 'pls_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_label_all, y_pred))\n",
    "accuracy_score(test_label_all,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 随机分组5折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier as RF                       # 随机森林\n",
    "def kFold_cv(X, y, classifier, **kwargs):\n",
    "    \"\"\"\n",
    "    :param X: 特征\n",
    "    :param y: 目标变量\n",
    "    :param classifier: 分类器\n",
    "    :param **kwargs: 参数\n",
    "    :return: 预测结果\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=5, shuffle=True) \n",
    "    y_pred = np.zeros(shape=(len(y),5))         # 初始化y_pred数组\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):  \n",
    "        X_train = X[train_index]    \n",
    "        X_test = X[test_index]\n",
    "        y_train = y[train_index]      # 划分数据集\n",
    "        clf = classifier(**kwargs)    \n",
    "        clf.fit(X_train, y_train)     # 模型训练\n",
    "        y_pred[test_index,:] = clf.predict(X_test)  # 模型预测\n",
    "    \n",
    "    return y_pred \n",
    "\n",
    "y_PRED = kFold_cv(datas.to_numpy(), labels.to_numpy(), RF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
